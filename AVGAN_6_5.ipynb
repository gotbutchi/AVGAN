{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "AVGAN_6.5.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/markus-weiss/AVGAN/blob/master/AVGAN_6_5.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8mYgLXpRaEIi",
        "colab_type": "text"
      },
      "source": [
        "#PREINSTALLING"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lB2usNzLZQQn",
        "colab_type": "code",
        "outputId": "57a171e2-3b63-41c9-dad2-cea329a958fe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 507
        }
      },
      "source": [
        "!pip install tensorflow-gpu==2.0.0-beta0"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting tensorflow-gpu==2.0.0-beta0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e8/7e/87c4c94686cda7066f52cbca4c344248516490acdd6b258ec6b8a805d956/tensorflow_gpu-2.0.0b0-cp36-cp36m-manylinux1_x86_64.whl (348.8MB)\n",
            "\u001b[K     |████████████████████████████████| 348.9MB 51kB/s \n",
            "\u001b[?25hRequirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-beta0) (1.15.0)\n",
            "Requirement already satisfied: numpy<2.0,>=1.14.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-beta0) (1.16.4)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-beta0) (0.7.1)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-beta0) (1.12.0)\n",
            "Collecting tb-nightly<1.14.0a20190604,>=1.14.0a20190603 (from tensorflow-gpu==2.0.0-beta0)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a4/96/571b875cd81dda9d5dfa1422a4f9d749e67c0a8d4f4f0b33a4e5f5f35e27/tb_nightly-1.14.0a20190603-py3-none-any.whl (3.1MB)\n",
            "\u001b[K     |████████████████████████████████| 3.1MB 26.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-beta0) (0.33.4)\n",
            "Collecting tf-estimator-nightly<1.14.0.dev2019060502,>=1.14.0.dev2019060501 (from tensorflow-gpu==2.0.0-beta0)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/32/dd/99c47dd007dcf10d63fd895611b063732646f23059c618a373e85019eb0e/tf_estimator_nightly-1.14.0.dev2019060501-py2.py3-none-any.whl (496kB)\n",
            "\u001b[K     |████████████████████████████████| 501kB 32.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-beta0) (0.8.0)\n",
            "Requirement already satisfied: gast>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-beta0) (0.2.2)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-beta0) (1.1.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-beta0) (1.1.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-beta0) (0.1.7)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-beta0) (1.11.2)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-beta0) (3.7.1)\n",
            "Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-beta0) (1.0.8)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.6/dist-packages (from tb-nightly<1.14.0a20190604,>=1.14.0a20190603->tensorflow-gpu==2.0.0-beta0) (41.0.1)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tb-nightly<1.14.0a20190604,>=1.14.0a20190603->tensorflow-gpu==2.0.0-beta0) (0.15.5)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tb-nightly<1.14.0a20190604,>=1.14.0a20190603->tensorflow-gpu==2.0.0-beta0) (3.1.1)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.6->tensorflow-gpu==2.0.0-beta0) (2.8.0)\n",
            "Installing collected packages: tb-nightly, tf-estimator-nightly, tensorflow-gpu\n",
            "Successfully installed tb-nightly-1.14.0a20190603 tensorflow-gpu-2.0.0b0 tf-estimator-nightly-1.14.0.dev2019060501\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Od2QlhGl0lQe",
        "colab_type": "code",
        "outputId": "4055b6c6-0c9f-4387-9e28-2bafc4c1d5ab",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84
        }
      },
      "source": [
        "!pip install imageio"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: imageio in /usr/local/lib/python3.6/dist-packages (2.4.1)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.6/dist-packages (from imageio) (4.3.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from imageio) (1.16.4)\n",
            "Requirement already satisfied: olefile in /usr/local/lib/python3.6/dist-packages (from pillow->imageio) (0.46)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "px-WP_3EZ2aK",
        "colab_type": "code",
        "outputId": "bcf9c218-b277-415a-c4ea-82a9960e2acc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        }
      },
      "source": [
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3h1IHgwfZ4Ya",
        "colab_type": "code",
        "outputId": "bf1f4a43-104f-4c8a-be86-a2b850bcfd67",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Change Directory to your Script\n",
        "cd /content/drive/My Drive/Colab Notebooks/AVGAN/"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/Colab Notebooks/AVGAN\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JGU4R003aCgt",
        "colab_type": "code",
        "outputId": "2dc6303b-5982-42c7-b846-5c11c3d7947f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "!ls\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "audio_output  AVGAN_6.5.ipynb  AVGAN_Versions  Images\ttraining_checkpoints\n",
            "Audios\t      AVGAN.gif        image_output    Images3\tTrainResult\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bgYmjannUxPw",
        "colab_type": "text"
      },
      "source": [
        "# IMPORTS"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PtkpTMvh1sC0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "tf.__version__\n",
        "\n",
        "import glob\n",
        "import imageio\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import os\n",
        "import PIL\n",
        "from tensorflow.keras import layers\n",
        "import time\n",
        "import matplotlib.image as mpimg\n",
        "from IPython import display"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nbWSVGU2suWJ",
        "colab_type": "text"
      },
      "source": [
        "#IMAGE READ IN and define DISCRIMINATOR"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZUyef-wtU04q",
        "colab_type": "text"
      },
      "source": [
        "## DataReadIn Image"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W_zdsrnwp4L3",
        "colab_type": "code",
        "outputId": "61ed729f-0f8f-455f-e918-02e4162e2220",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "def GetListOfFiles(dirName):\n",
        "  # create a list of file and sub directories \n",
        "  # names in the given directory \n",
        "  listOfFile = os.listdir(dirName)\n",
        "  allFiles = list()\n",
        "  # Iterate over all the entries\n",
        "  for entry in listOfFile:\n",
        "      # Create full path\n",
        "      fullPath = os.path.join(dirName, entry)\n",
        "      # If entry is a directory then get the list of files in this directory \n",
        "      if os.path.isdir(fullPath):\n",
        "          allFiles = allFiles + getListOfFiles(fullPath)\n",
        "      else:\n",
        "          allFiles.append(fullPath)\n",
        "\n",
        "  return allFiles\n",
        "\n",
        "def ImageReadIn(image_list):\n",
        "  image_array = [len(image_list),600,800,3]\n",
        "  for item in image_list:\n",
        "    import cv2 \n",
        "    image = cv2.imread(item)\n",
        "    reshaped_image = image\n",
        "    image_array[0] = image\n",
        "\n",
        "  return image_array\n",
        "\n",
        "def ConvertToTensor(image_list, image_count):\n",
        "  import numpy as np\n",
        "  ndarray = np.ones([image_count,600,800,3])\n",
        "\n",
        "  ndarray[0,:,:,:] = image_list[0]\n",
        "\n",
        "  n=0\n",
        "  for item in image_list:\n",
        "    ndarray[n,:,:,:] = image_list[n]\n",
        "    n=n+1\n",
        "\n",
        "  # TO CHECK THAT THE DATA IS RIGHT\n",
        "  #print(ndarray[:,0,0,0])\n",
        "\n",
        "  # CONVERT A NUMPY ARRAY TO A TENSOR\n",
        "  img_tensor = tf.add(ndarray, 1)\n",
        "  tensor_reshape = tf.image.resize(img_tensor, [224, 224])\n",
        "\n",
        "  return tf.convert_to_tensor(tensor_reshape, np.float32)\n",
        "\n",
        "\n",
        "  \n",
        "  \n",
        "  \n",
        "image_data_root = \"Images3/\"\n",
        "image_list = GetListOfFiles(image_data_root)\n",
        "\n",
        "print(image_list)\n",
        "\n",
        "image_data_array = ImageReadIn(image_list)\n",
        "\n",
        "image_count = len(image_list)\n",
        "#print(image_count)\n",
        "image_dataset = ConvertToTensor(image_data_array,image_count)\n",
        "\n",
        "print(image_dataset.shape)\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['Images3/2019-01-18T08_23_23.724Z.jpg', 'Images3/2019-01-18T08_23_23.724Z (1).jpg', 'Images3/2019-01-18T08_28_04.262Z.jpg', 'Images3/2019-01-18T08_28_04.262Z (2).jpg']\n",
            "(4, 224, 224, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W3UMRqUVsjbq",
        "colab_type": "text"
      },
      "source": [
        "##Define IMAGE convolution"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DAeH163Ma8Uj",
        "colab_type": "code",
        "outputId": "65360a6c-7841-41b6-dcd7-8a8117a9fdd6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "def discriminator_Image():\n",
        "  model = tf.keras.Sequential()\n",
        "  model.add(layers.Conv2D(32, (3,3), strides = (1,1), padding = 'same', input_shape= [224,224,3]))\n",
        "  model.add(layers.LeakyReLU())\n",
        "\n",
        "\n",
        "  model.add(layers.MaxPooling2D(2, 2))\n",
        "  model.add(layers.Conv2D(64, (3,3), strides = (1,1), padding = 'same'))\n",
        "  model.add(layers.LeakyReLU())\n",
        "  \n",
        "  model.add(layers.MaxPooling2D(2, 2))\n",
        "  model.add(layers.Conv2D(128, (3,3), strides = (1,1), padding = 'same'))\n",
        "  model.add(layers.LeakyReLU())\n",
        "  model.add(layers.MaxPooling2D(2, 2))\n",
        "  for layer in model.layers:\n",
        "    aA=layer.output_shape\n",
        "    bA=layer.output\n",
        "    #print(aA)\n",
        "    #print(bA)\n",
        "  \n",
        "  return model\n",
        "\n",
        "\n",
        "\n",
        "discriminator_image = discriminator_Image()\n",
        "discriminator_image(image_dataset)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: id=131, shape=(4, 28, 28, 128), dtype=float32, numpy=\n",
              "array([[[[ 1.43430824e+01,  9.91328812e+00, -1.55021133e+01, ...,\n",
              "           3.74936905e+01,  4.41251717e+01,  2.25181122e+01],\n",
              "         [ 1.34301481e+01, -1.31165415e-01, -1.70418434e+01, ...,\n",
              "           3.02650280e+01,  3.21991539e+01,  1.50405073e+01],\n",
              "         [ 1.33916683e+01, -2.72766739e-01, -1.69059105e+01, ...,\n",
              "           2.96616344e+01,  3.18203125e+01,  1.52013702e+01],\n",
              "         ...,\n",
              "         [ 1.13178911e+01, -5.90538025e-01, -1.02704163e+01, ...,\n",
              "           1.69616604e+01,  2.81027145e+01,  9.69812870e+00],\n",
              "         [ 1.07593641e+01, -7.28786826e-01, -1.04905262e+01, ...,\n",
              "           1.92929668e+01,  2.80352058e+01,  1.01090832e+01],\n",
              "         [ 1.30444927e+01,  1.52013750e+01, -4.32993174e+00, ...,\n",
              "           3.08423538e+01,  2.95043583e+01,  1.70216255e+01]],\n",
              "\n",
              "        [[ 1.10769396e+01,  1.01931095e+01, -1.62674313e+01, ...,\n",
              "           3.44778709e+01,  4.44318619e+01,  1.92319641e+01],\n",
              "         [ 4.34719610e+00,  2.14972520e+00, -1.87327995e+01, ...,\n",
              "           2.81961079e+01,  2.13531570e+01,  1.31342897e+01],\n",
              "         [ 4.70102406e+00,  2.07884383e+00, -1.85319061e+01, ...,\n",
              "           2.80920086e+01,  2.15017967e+01,  1.29966364e+01],\n",
              "         ...,\n",
              "         [ 7.01979733e+00,  7.01374817e+00, -1.17969341e+01, ...,\n",
              "           2.29109325e+01,  1.74298344e+01,  1.18642426e+01],\n",
              "         [ 7.56798315e+00,  7.44214964e+00, -1.06228809e+01, ...,\n",
              "           2.29090195e+01,  1.72522373e+01,  1.22107410e+01],\n",
              "         [ 8.32098198e+00,  2.13457718e+01, -4.35318518e+00, ...,\n",
              "           2.92058792e+01,  2.40569801e+01,  1.54375324e+01]],\n",
              "\n",
              "        [[ 1.14633179e+01,  1.02779140e+01, -1.44496956e+01, ...,\n",
              "           3.25064011e+01,  4.23548851e+01,  1.96108341e+01],\n",
              "         [ 4.66611147e+00,  4.61713219e+00, -1.68926811e+01, ...,\n",
              "           2.57786884e+01,  2.17620525e+01,  1.45256786e+01],\n",
              "         [ 4.45230913e+00,  4.52234221e+00, -1.69959965e+01, ...,\n",
              "           2.62460690e+01,  2.12602024e+01,  1.56570339e+01],\n",
              "         ...,\n",
              "         [ 5.78631735e+00,  8.83597374e+00, -9.82969856e+00, ...,\n",
              "           1.53162689e+01,  1.53015327e+01,  1.45157681e+01],\n",
              "         [ 6.29556274e+00,  7.66694450e+00, -9.34734154e+00, ...,\n",
              "           1.35507488e+01,  1.44695520e+01,  1.24538155e+01],\n",
              "         [ 7.06810093e+00,  1.21505222e+01, -4.61864948e+00, ...,\n",
              "           2.19783401e+01,  1.87375145e+01,  1.37975569e+01]],\n",
              "\n",
              "        ...,\n",
              "\n",
              "        [[ 1.39950657e+01,  1.39928589e+01, -1.60961208e+01, ...,\n",
              "           4.44138107e+01,  5.67456131e+01,  3.19120216e+01],\n",
              "         [ 5.69395447e+00,  6.18894863e+00, -1.45056734e+01, ...,\n",
              "           3.18950691e+01,  2.03234310e+01,  2.04182758e+01],\n",
              "         [ 3.24093723e+00,  5.45076084e+00, -1.29408903e+01, ...,\n",
              "           2.50758018e+01,  1.25243711e+01,  1.25226860e+01],\n",
              "         ...,\n",
              "         [ 9.83403778e+00,  3.82072115e+00, -7.75477648e+00, ...,\n",
              "           8.07065201e+00,  1.68627701e+01,  1.25440550e+01],\n",
              "         [ 1.04425011e+01,  4.24836349e+00, -8.98431587e+00, ...,\n",
              "           1.00070705e+01,  1.93800182e+01,  1.54688578e+01],\n",
              "         [ 9.91943359e+00,  1.24419003e+01, -4.72498703e+00, ...,\n",
              "           2.02883911e+01,  2.21313953e+01,  1.79291649e+01]],\n",
              "\n",
              "        [[ 1.76804752e+01,  2.38404388e+01, -2.12148056e+01, ...,\n",
              "           5.28407555e+01,  6.17223511e+01,  2.92901649e+01],\n",
              "         [ 7.32671118e+00,  1.91447735e+01, -1.65389481e+01, ...,\n",
              "           4.09193764e+01,  1.94861298e+01,  8.96690083e+00],\n",
              "         [ 5.12695694e+00,  5.49704742e+00, -1.28848467e+01, ...,\n",
              "           2.23910522e+01,  1.94095268e+01,  1.05971909e+01],\n",
              "         ...,\n",
              "         [ 8.61246109e+00,  1.80099487e+00, -7.24749899e+00, ...,\n",
              "           6.65451765e+00,  1.72459011e+01,  1.18060198e+01],\n",
              "         [ 9.86989975e+00,  4.21466398e+00, -9.56339359e+00, ...,\n",
              "           8.04154205e+00,  2.02185974e+01,  1.59433489e+01],\n",
              "         [ 1.02939892e+01,  1.68272686e+01, -5.35983372e+00, ...,\n",
              "           2.02393436e+01,  2.57970161e+01,  1.75203381e+01]],\n",
              "\n",
              "        [[ 9.14915276e+00,  1.98441162e+01, -8.04651260e+00, ...,\n",
              "           4.93545380e+01,  4.39438667e+01,  2.71744804e+01],\n",
              "         [ 3.25337648e+00,  1.90471401e+01, -8.31406307e+00, ...,\n",
              "           4.24077301e+01,  1.22162304e+01,  1.97026806e+01],\n",
              "         [ 5.58670664e+00,  1.14302101e+01, -8.53807163e+00, ...,\n",
              "           3.17854824e+01,  1.61114540e+01,  1.26080856e+01],\n",
              "         ...,\n",
              "         [ 8.65938950e+00,  1.44909286e+00, -6.03048277e+00, ...,\n",
              "           1.23526859e+01,  1.74356136e+01,  1.35718517e+01],\n",
              "         [ 1.25771561e+01,  5.11287642e+00, -7.79440689e+00, ...,\n",
              "           1.73742733e+01,  2.04677467e+01,  1.52743979e+01],\n",
              "         [ 1.21817999e+01,  1.44186277e+01, -4.14206171e+00, ...,\n",
              "           2.13834839e+01,  2.16550465e+01,  1.44507771e+01]]],\n",
              "\n",
              "\n",
              "       [[[ 5.05760384e+01,  3.60442657e+01, -5.40794106e+01, ...,\n",
              "           1.34581467e+02,  1.55926636e+02,  8.12696762e+01],\n",
              "         [ 4.81848755e+01,  2.08547592e-01, -6.01508942e+01, ...,\n",
              "           1.06891869e+02,  1.14821617e+02,  5.55763054e+01],\n",
              "         [ 4.81848755e+01,  2.08547592e-01, -6.01508942e+01, ...,\n",
              "           1.06891869e+02,  1.14821617e+02,  5.55763054e+01],\n",
              "         ...,\n",
              "         [ 4.81848755e+01,  2.08547592e-01, -6.01508942e+01, ...,\n",
              "           1.06891869e+02,  1.14821617e+02,  5.55763054e+01],\n",
              "         [ 4.81848755e+01,  2.08547592e-01, -6.01508942e+01, ...,\n",
              "           1.06891869e+02,  1.14821617e+02,  5.55763054e+01],\n",
              "         [ 5.77650719e+01,  9.10985870e+01, -2.50707054e+01, ...,\n",
              "           1.66236359e+02,  1.20091705e+02,  9.18250885e+01]],\n",
              "\n",
              "        [[ 3.98748817e+01,  3.67148056e+01, -5.77988739e+01, ...,\n",
              "           1.21964409e+02,  1.57869446e+02,  6.55451584e+01],\n",
              "         [ 1.36715517e+01,  5.23066521e+00, -6.55281143e+01, ...,\n",
              "           9.53142929e+01,  7.37090683e+01,  4.44029007e+01],\n",
              "         [ 1.36715517e+01,  5.23066521e+00, -6.55281143e+01, ...,\n",
              "           9.53142929e+01,  7.37090683e+01,  4.44029007e+01],\n",
              "         ...,\n",
              "         [ 1.36715517e+01,  5.23066521e+00, -6.55281143e+01, ...,\n",
              "           9.53142929e+01,  7.37090683e+01,  4.44029007e+01],\n",
              "         [ 1.36715517e+01,  5.23066521e+00, -6.55281143e+01, ...,\n",
              "           9.53142929e+01,  7.37090683e+01,  4.44029007e+01],\n",
              "         [ 2.35283470e+01,  8.69995422e+01, -3.32954063e+01, ...,\n",
              "           1.69356796e+02,  1.05499908e+02,  8.36752243e+01]],\n",
              "\n",
              "        [[ 3.98748817e+01,  3.67148056e+01, -5.77988739e+01, ...,\n",
              "           1.21964409e+02,  1.57869446e+02,  6.55451584e+01],\n",
              "         [ 1.36715517e+01,  5.23066521e+00, -6.55281143e+01, ...,\n",
              "           9.53142929e+01,  7.37090683e+01,  4.44029007e+01],\n",
              "         [ 1.36715517e+01,  5.23066521e+00, -6.55281143e+01, ...,\n",
              "           9.53142929e+01,  7.37090683e+01,  4.44029007e+01],\n",
              "         ...,\n",
              "         [ 1.36715517e+01,  5.23066521e+00, -6.55281143e+01, ...,\n",
              "           9.53142929e+01,  7.37090683e+01,  4.44029007e+01],\n",
              "         [ 1.36715517e+01,  5.23066521e+00, -6.55281143e+01, ...,\n",
              "           9.53142929e+01,  7.37090683e+01,  4.44029007e+01],\n",
              "         [ 2.35283470e+01,  8.69995422e+01, -3.32954063e+01, ...,\n",
              "           1.69356796e+02,  1.05499908e+02,  8.36752243e+01]],\n",
              "\n",
              "        ...,\n",
              "\n",
              "        [[ 3.98748817e+01,  3.67148056e+01, -5.77988739e+01, ...,\n",
              "           1.21964409e+02,  1.57869446e+02,  6.55451584e+01],\n",
              "         [ 1.36715517e+01,  5.23066521e+00, -6.55281143e+01, ...,\n",
              "           9.53142929e+01,  7.37090683e+01,  4.44029007e+01],\n",
              "         [ 1.36715517e+01,  5.23066521e+00, -6.55281143e+01, ...,\n",
              "           9.53142929e+01,  7.37090683e+01,  4.44029007e+01],\n",
              "         ...,\n",
              "         [ 1.36715517e+01,  5.23066521e+00, -6.55281143e+01, ...,\n",
              "           9.53142929e+01,  7.37090683e+01,  4.44029007e+01],\n",
              "         [ 1.36715517e+01,  5.23066521e+00, -6.55281143e+01, ...,\n",
              "           9.53142929e+01,  7.37090683e+01,  4.44029007e+01],\n",
              "         [ 2.35283470e+01,  8.69995422e+01, -3.32954063e+01, ...,\n",
              "           1.69356796e+02,  1.05499908e+02,  8.36752243e+01]],\n",
              "\n",
              "        [[ 3.98748817e+01,  3.67148056e+01, -5.77988739e+01, ...,\n",
              "           1.21964409e+02,  1.57869446e+02,  6.55451584e+01],\n",
              "         [ 1.36715517e+01,  5.23066521e+00, -6.55281143e+01, ...,\n",
              "           9.53142929e+01,  7.37090683e+01,  4.44029007e+01],\n",
              "         [ 1.36715517e+01,  5.23066521e+00, -6.55281143e+01, ...,\n",
              "           9.53142929e+01,  7.37090683e+01,  4.44029007e+01],\n",
              "         ...,\n",
              "         [ 1.36715517e+01,  5.23066521e+00, -6.55281143e+01, ...,\n",
              "           9.53142929e+01,  7.37090683e+01,  4.44029007e+01],\n",
              "         [ 1.36715517e+01,  5.23066521e+00, -6.55281143e+01, ...,\n",
              "           9.53142929e+01,  7.37090683e+01,  4.44029007e+01],\n",
              "         [ 2.35283470e+01,  8.69995422e+01, -3.32954063e+01, ...,\n",
              "           1.69356796e+02,  1.05499908e+02,  8.36752243e+01]],\n",
              "\n",
              "        [[ 4.26729012e+01,  4.35186653e+01, -4.49697495e+01, ...,\n",
              "           1.47213257e+02,  1.47458405e+02,  8.41336060e+01],\n",
              "         [ 2.59419174e+01,  3.67525444e+01, -5.39332085e+01, ...,\n",
              "           1.22763374e+02,  7.21301422e+01,  6.21759109e+01],\n",
              "         [ 2.59419174e+01,  3.67525444e+01, -5.39332085e+01, ...,\n",
              "           1.22763374e+02,  7.21301422e+01,  6.21759109e+01],\n",
              "         ...,\n",
              "         [ 2.59419174e+01,  3.67525444e+01, -5.39332085e+01, ...,\n",
              "           1.22763374e+02,  7.21301422e+01,  6.21759109e+01],\n",
              "         [ 2.59419174e+01,  3.67525444e+01, -5.39332085e+01, ...,\n",
              "           1.22763374e+02,  7.21301422e+01,  6.21759109e+01],\n",
              "         [ 3.15375576e+01,  1.03615570e+02, -3.01170368e+01, ...,\n",
              "           1.81142792e+02,  1.11165970e+02,  1.07277481e+02]]],\n",
              "\n",
              "\n",
              "       [[[ 6.74066620e+01,  4.80389748e+01, -7.20758972e+01, ...,\n",
              "           1.79367386e+02,  2.07815704e+02,  1.08314507e+02],\n",
              "         [ 6.42197495e+01,  2.77938843e-01, -8.01678467e+01, ...,\n",
              "           1.42463257e+02,  1.53031815e+02,  7.40709610e+01],\n",
              "         [ 6.42197495e+01,  2.77938843e-01, -8.01678467e+01, ...,\n",
              "           1.42463257e+02,  1.53031815e+02,  7.40709610e+01],\n",
              "         ...,\n",
              "         [ 6.42197495e+01,  2.77938843e-01, -8.01678467e+01, ...,\n",
              "           1.42463257e+02,  1.53031815e+02,  7.40709610e+01],\n",
              "         [ 6.42197495e+01,  2.77938843e-01, -8.01678467e+01, ...,\n",
              "           1.42463257e+02,  1.53031815e+02,  7.40709610e+01],\n",
              "         [ 7.69880829e+01,  1.21414276e+02, -3.34137192e+01, ...,\n",
              "           2.21556274e+02,  1.60055573e+02,  1.22382515e+02]],\n",
              "\n",
              "        [[ 5.31444016e+01,  4.89326859e+01, -7.70331039e+01, ...,\n",
              "           1.62551605e+02,  2.10405029e+02,  8.73572006e+01],\n",
              "         [ 1.82211514e+01,  6.97132730e+00, -8.73344727e+01, ...,\n",
              "           1.27032845e+02,  9.82378616e+01,  5.91792412e+01],\n",
              "         [ 1.82211514e+01,  6.97132730e+00, -8.73344727e+01, ...,\n",
              "           1.27032845e+02,  9.82378616e+01,  5.91792412e+01],\n",
              "         ...,\n",
              "         [ 1.82211514e+01,  6.97132730e+00, -8.73344727e+01, ...,\n",
              "           1.27032845e+02,  9.82378616e+01,  5.91792412e+01],\n",
              "         [ 1.82211514e+01,  6.97132730e+00, -8.73344727e+01, ...,\n",
              "           1.27032845e+02,  9.82378616e+01,  5.91792412e+01],\n",
              "         [ 3.13580723e+01,  1.15951118e+02, -4.43753967e+01, ...,\n",
              "           2.25715179e+02,  1.40608032e+02,  1.11520538e+02]],\n",
              "\n",
              "        [[ 5.31444016e+01,  4.89326859e+01, -7.70331039e+01, ...,\n",
              "           1.62551605e+02,  2.10405029e+02,  8.73572006e+01],\n",
              "         [ 1.82211514e+01,  6.97132730e+00, -8.73344727e+01, ...,\n",
              "           1.27032845e+02,  9.82378616e+01,  5.91792412e+01],\n",
              "         [ 1.82211514e+01,  6.97132730e+00, -8.73344727e+01, ...,\n",
              "           1.27032845e+02,  9.82378616e+01,  5.91792412e+01],\n",
              "         ...,\n",
              "         [ 1.82211514e+01,  6.97132730e+00, -8.73344727e+01, ...,\n",
              "           1.27032845e+02,  9.82378616e+01,  5.91792412e+01],\n",
              "         [ 1.82211514e+01,  6.97132730e+00, -8.73344727e+01, ...,\n",
              "           1.27032845e+02,  9.82378616e+01,  5.91792412e+01],\n",
              "         [ 3.13580723e+01,  1.15951118e+02, -4.43753967e+01, ...,\n",
              "           2.25715179e+02,  1.40608032e+02,  1.11520538e+02]],\n",
              "\n",
              "        ...,\n",
              "\n",
              "        [[ 5.31444016e+01,  4.89326859e+01, -7.70331039e+01, ...,\n",
              "           1.62551605e+02,  2.10405029e+02,  8.73572006e+01],\n",
              "         [ 1.82211514e+01,  6.97132730e+00, -8.73344727e+01, ...,\n",
              "           1.27032845e+02,  9.82378616e+01,  5.91792412e+01],\n",
              "         [ 1.82211514e+01,  6.97132730e+00, -8.73344727e+01, ...,\n",
              "           1.27032845e+02,  9.82378616e+01,  5.91792412e+01],\n",
              "         ...,\n",
              "         [ 1.82211514e+01,  6.97132730e+00, -8.73344727e+01, ...,\n",
              "           1.27032845e+02,  9.82378616e+01,  5.91792412e+01],\n",
              "         [ 1.82211514e+01,  6.97132730e+00, -8.73344727e+01, ...,\n",
              "           1.27032845e+02,  9.82378616e+01,  5.91792412e+01],\n",
              "         [ 3.13580723e+01,  1.15951118e+02, -4.43753967e+01, ...,\n",
              "           2.25715179e+02,  1.40608032e+02,  1.11520538e+02]],\n",
              "\n",
              "        [[ 5.31444016e+01,  4.89326859e+01, -7.70331039e+01, ...,\n",
              "           1.62551605e+02,  2.10405029e+02,  8.73572006e+01],\n",
              "         [ 1.82211514e+01,  6.97132730e+00, -8.73344727e+01, ...,\n",
              "           1.27032845e+02,  9.82378616e+01,  5.91792412e+01],\n",
              "         [ 1.82211514e+01,  6.97132730e+00, -8.73344727e+01, ...,\n",
              "           1.27032845e+02,  9.82378616e+01,  5.91792412e+01],\n",
              "         ...,\n",
              "         [ 1.82211514e+01,  6.97132730e+00, -8.73344727e+01, ...,\n",
              "           1.27032845e+02,  9.82378616e+01,  5.91792412e+01],\n",
              "         [ 1.82211514e+01,  6.97132730e+00, -8.73344727e+01, ...,\n",
              "           1.27032845e+02,  9.82378616e+01,  5.91792412e+01],\n",
              "         [ 3.13580723e+01,  1.15951118e+02, -4.43753967e+01, ...,\n",
              "           2.25715179e+02,  1.40608032e+02,  1.11520538e+02]],\n",
              "\n",
              "        [[ 5.68735275e+01,  5.80007133e+01, -5.99347191e+01, ...,\n",
              "           1.96202682e+02,  1.96529419e+02,  1.12131485e+02],\n",
              "         [ 3.45748138e+01,  4.89830399e+01, -7.18810501e+01, ...,\n",
              "           1.63616455e+02,  9.61334839e+01,  8.28667145e+01],\n",
              "         [ 3.45748138e+01,  4.89830399e+01, -7.18810501e+01, ...,\n",
              "           1.63616455e+02,  9.61334839e+01,  8.28667145e+01],\n",
              "         ...,\n",
              "         [ 3.45748138e+01,  4.89830399e+01, -7.18810501e+01, ...,\n",
              "           1.63616455e+02,  9.61334839e+01,  8.28667145e+01],\n",
              "         [ 3.45748138e+01,  4.89830399e+01, -7.18810501e+01, ...,\n",
              "           1.63616455e+02,  9.61334839e+01,  8.28667145e+01],\n",
              "         [ 4.20326042e+01,  1.38096619e+02, -4.01393280e+01, ...,\n",
              "           2.41423370e+02,  1.48159607e+02,  1.42977127e+02]]],\n",
              "\n",
              "\n",
              "       [[[ 3.36612314e-01,  2.39895165e-01, -3.59929562e-01, ...,\n",
              "           8.95717442e-01,  1.03778136e+00,  5.40896654e-01],\n",
              "         [ 3.20697874e-01,  1.38800591e-03, -4.00338680e-01, ...,\n",
              "           7.11427033e-01,  7.64203727e-01,  3.69892448e-01],\n",
              "         [ 3.20697874e-01,  1.38800591e-03, -4.00338680e-01, ...,\n",
              "           7.11427033e-01,  7.64203727e-01,  3.69892448e-01],\n",
              "         ...,\n",
              "         [ 3.20697874e-01,  1.38800591e-03, -4.00338680e-01, ...,\n",
              "           7.11427033e-01,  7.64203727e-01,  3.69892448e-01],\n",
              "         [ 3.20697874e-01,  1.38800591e-03, -4.00338680e-01, ...,\n",
              "           7.11427033e-01,  7.64203727e-01,  3.69892448e-01],\n",
              "         [ 3.84459734e-01,  6.06313527e-01, -1.66860029e-01, ...,\n",
              "           1.10639811e+00,  7.99278975e-01,  6.11148834e-01]],\n",
              "\n",
              "        [[ 2.65390188e-01,  2.44358063e-01, -3.84684712e-01, ...,\n",
              "           8.11743200e-01,  1.05071199e+00,  4.36240822e-01],\n",
              "         [ 9.09920633e-02,  3.48131694e-02, -4.36127245e-01, ...,\n",
              "           6.34371519e-01,  4.90576386e-01,  2.95526683e-01],\n",
              "         [ 9.09920633e-02,  3.48131694e-02, -4.36127245e-01, ...,\n",
              "           6.34371519e-01,  4.90576386e-01,  2.95526683e-01],\n",
              "         ...,\n",
              "         [ 9.09920633e-02,  3.48131694e-02, -4.36127245e-01, ...,\n",
              "           6.34371519e-01,  4.90576386e-01,  2.95526683e-01],\n",
              "         [ 9.09920633e-02,  3.48131694e-02, -4.36127245e-01, ...,\n",
              "           6.34371519e-01,  4.90576386e-01,  2.95526683e-01],\n",
              "         [ 1.56594679e-01,  5.79032063e-01, -2.21599981e-01, ...,\n",
              "           1.12716687e+00,  7.02162564e-01,  5.56906521e-01]],\n",
              "\n",
              "        [[ 2.65390188e-01,  2.44358063e-01, -3.84684712e-01, ...,\n",
              "           8.11743200e-01,  1.05071199e+00,  4.36240822e-01],\n",
              "         [ 9.09920633e-02,  3.48131694e-02, -4.36127245e-01, ...,\n",
              "           6.34371519e-01,  4.90576386e-01,  2.95526683e-01],\n",
              "         [ 9.09920633e-02,  3.48131694e-02, -4.36127245e-01, ...,\n",
              "           6.34371519e-01,  4.90576386e-01,  2.95526683e-01],\n",
              "         ...,\n",
              "         [ 9.09920633e-02,  3.48131694e-02, -4.36127245e-01, ...,\n",
              "           6.34371519e-01,  4.90576386e-01,  2.95526683e-01],\n",
              "         [ 9.09920633e-02,  3.48131694e-02, -4.36127245e-01, ...,\n",
              "           6.34371519e-01,  4.90576386e-01,  2.95526683e-01],\n",
              "         [ 1.56594679e-01,  5.79032063e-01, -2.21599981e-01, ...,\n",
              "           1.12716687e+00,  7.02162564e-01,  5.56906521e-01]],\n",
              "\n",
              "        ...,\n",
              "\n",
              "        [[ 2.65390188e-01,  2.44358063e-01, -3.84684712e-01, ...,\n",
              "           8.11743200e-01,  1.05071199e+00,  4.36240822e-01],\n",
              "         [ 9.09920633e-02,  3.48131694e-02, -4.36127245e-01, ...,\n",
              "           6.34371519e-01,  4.90576386e-01,  2.95526683e-01],\n",
              "         [ 9.09920633e-02,  3.48131694e-02, -4.36127245e-01, ...,\n",
              "           6.34371519e-01,  4.90576386e-01,  2.95526683e-01],\n",
              "         ...,\n",
              "         [ 9.09920633e-02,  3.48131694e-02, -4.36127245e-01, ...,\n",
              "           6.34371519e-01,  4.90576386e-01,  2.95526683e-01],\n",
              "         [ 9.09920633e-02,  3.48131694e-02, -4.36127245e-01, ...,\n",
              "           6.34371519e-01,  4.90576386e-01,  2.95526683e-01],\n",
              "         [ 1.56594679e-01,  5.79032063e-01, -2.21599981e-01, ...,\n",
              "           1.12716687e+00,  7.02162564e-01,  5.56906521e-01]],\n",
              "\n",
              "        [[ 2.65390188e-01,  2.44358063e-01, -3.84684712e-01, ...,\n",
              "           8.11743200e-01,  1.05071199e+00,  4.36240822e-01],\n",
              "         [ 9.09920633e-02,  3.48131694e-02, -4.36127245e-01, ...,\n",
              "           6.34371519e-01,  4.90576386e-01,  2.95526683e-01],\n",
              "         [ 9.09920633e-02,  3.48131694e-02, -4.36127245e-01, ...,\n",
              "           6.34371519e-01,  4.90576386e-01,  2.95526683e-01],\n",
              "         ...,\n",
              "         [ 9.09920633e-02,  3.48131694e-02, -4.36127245e-01, ...,\n",
              "           6.34371519e-01,  4.90576386e-01,  2.95526683e-01],\n",
              "         [ 9.09920633e-02,  3.48131694e-02, -4.36127245e-01, ...,\n",
              "           6.34371519e-01,  4.90576386e-01,  2.95526683e-01],\n",
              "         [ 1.56594679e-01,  5.79032063e-01, -2.21599981e-01, ...,\n",
              "           1.12716687e+00,  7.02162564e-01,  5.56906521e-01]],\n",
              "\n",
              "        [[ 2.84012586e-01,  2.89641798e-01, -2.99299568e-01, ...,\n",
              "           9.79789019e-01,  9.81420338e-01,  5.59957206e-01],\n",
              "         [ 1.72658235e-01,  2.44609296e-01, -3.58956456e-01, ...,\n",
              "           8.17060590e-01,  4.80067372e-01,  4.13816273e-01],\n",
              "         [ 1.72658235e-01,  2.44609296e-01, -3.58956456e-01, ...,\n",
              "           8.17060590e-01,  4.80067372e-01,  4.13816273e-01],\n",
              "         ...,\n",
              "         [ 1.72658235e-01,  2.44609296e-01, -3.58956456e-01, ...,\n",
              "           8.17060590e-01,  4.80067372e-01,  4.13816273e-01],\n",
              "         [ 1.72658235e-01,  2.44609296e-01, -3.58956456e-01, ...,\n",
              "           8.17060590e-01,  4.80067372e-01,  4.13816273e-01],\n",
              "         [ 2.09900603e-01,  6.89621091e-01, -2.00446352e-01, ...,\n",
              "           1.20560992e+00,  7.39873648e-01,  7.13993192e-01]]]],\n",
              "      dtype=float32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dprk2EIRfpxz",
        "colab_type": "text"
      },
      "source": [
        "#AUDIO READ IN and define DISCRIMINATOR"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dvUPQG2igTjF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Here we need the function that converts Wave to images "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pTcWT3hcP5fM",
        "colab_type": "text"
      },
      "source": [
        "##Read Files and Concatenate\n",
        "Pleas remember that every file with the same number will be concatenate"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "md6QSnfwh8eK",
        "colab_type": "code",
        "outputId": "ac912158-8f69-475b-f825-f919b157109d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "def getListOfFiles(dirName):\n",
        "  # create a list of file and sub directories \n",
        "  # names in the given directory \n",
        "  listOfFile = os.listdir(dirName)\n",
        "  allFiles = list()\n",
        "  # Iterate over all the entries\n",
        "  for entry in listOfFile:\n",
        "      # Create full path\n",
        "      fullPath = os.path.join(dirName, entry)\n",
        "      # If entry is a directory then get the list of files in this directory \n",
        "      if os.path.isdir(fullPath):\n",
        "          allFiles = allFiles + getListOfFiles(fullPath)\n",
        "      else:\n",
        "          allFiles.append(fullPath)\n",
        "\n",
        "  return allFiles\n",
        "  \n",
        "  \n",
        "# Not stable is pre alpha cause when the pictures not directly inumeratet \n",
        "# [102. 150. 102.   3.] this output is not good but if you print out the data concat read in you find the error but why\n",
        "# for item in audioList:\n",
        "#  print(item)\n",
        "\n",
        "\n",
        "def rgb2gray(rgb):\n",
        "    return np.dot(rgb[...,:3], [0.299, 0.587, 0.114])\n",
        "\n",
        "  \n",
        "def From6to2Dimensions(log,phase):\n",
        "   \n",
        "  log = rgb2gray(log) \n",
        "  phase = rgb2gray(phase) \n",
        "\n",
        "  reshapeAudioImage = np.ndarray((224,224,2))\n",
        "  reshapeAudioImage[:,:,0] = log[:,:]\n",
        "  reshapeAudioImage[:,:,1] = phase[:,:]\n",
        "  \n",
        "  return reshapeAudioImage\n",
        "  \n",
        "\n",
        "\n",
        "\n",
        "def ConcatAllPairsInFolder(audiolist):\n",
        "  n = 1\n",
        "  concatAudioImage = [len(audioList)/2,224,224,6]\n",
        "  for item in audioList:\n",
        "    #print(n)\n",
        "\n",
        "    import re\n",
        "    r = re.compile('.*_' + str(n) +'.jpg')\n",
        "    pair = list(filter(r.match, audioList)) # Read Note\n",
        "    #print(pair[0],\" \",pair[1])\n",
        "    #print(pair)\n",
        "    \n",
        "\n",
        "    import cv2 \n",
        "    log     = cv2.imread(pair[0])  \n",
        "    phase   = cv2.imread(pair[1])\n",
        "\n",
        "    \n",
        "    \n",
        "    #import tensorflow as tf\n",
        "    # dimension 2 IS RIGHT ????\n",
        "    #LogPhaseCon = tf.concat([log,phase],2)\n",
        "    #print(LogPhaseCon)\n",
        "\n",
        "    concatAudioImage[n-1] = From6to2Dimensions(log,phase)\n",
        "    \n",
        "\n",
        "\n",
        "    if n >= len(audioList)/2:\n",
        "      return concatAudioImage\n",
        "      break\n",
        "    else:\n",
        "      n=n+1\n",
        "      \n",
        "\n",
        "\n",
        "def ConvertToTensor(concatImageAudioList, audioimageCount):\n",
        "  import numpy as np\n",
        "  ndarray = np.ones([audioimageCount,224,224,2])\n",
        "  \n",
        "  # Convert color to grey 6 - 2 channel\n",
        "\n",
        "  ndarray[0,:,:,:] = concatImageAudioList[0]\n",
        "\n",
        "  n=0\n",
        "  for item in concatImageAudioList:\n",
        "    ndarray[n,:,:,:] = concatImageAudioList[n]\n",
        "    n=n+1\n",
        "\n",
        "  # TO CHECK THAT THE DATA IS RIGHT\n",
        "  #print(ndarray[:,0,0,0])\n",
        "\n",
        "  # CONVERT A NUMPY ARRAY TO A TENSOR\n",
        "  tensor = tf.add(ndarray, 1)\n",
        "  #print(tensor.shape)\n",
        "  #print(tensor[3])\n",
        "\n",
        "\n",
        "  #tf.convert_to_tensor([ndarray, 1, 1, 64])\n",
        "  return tf.convert_to_tensor(ndarray, np.float32)\n",
        "  #type(data_tf)\n",
        "  #sess = tf.compat.v1.InteractiveSession()\n",
        "  #print(data_tf.numpy())\n",
        "  #sess.close()\n",
        "\n",
        "  \n",
        "\n",
        "audioFolder = 'Audios/'\n",
        "audioList = getListOfFiles(audioFolder)\n",
        "\n",
        "concatImageAudioList = ConcatAllPairsInFolder(audioList)\n",
        "#print(concatImageAudioList)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "audioimageCount = len(concatImageAudioList)\n",
        "data_tf = ConvertToTensor(concatImageAudioList,audioimageCount)\n",
        "\n",
        " \n",
        "audioImage_dataSet = data_tf\n",
        "print(audioImage_dataSet.shape)\n",
        "type(audioImage_dataSet)\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(4, 224, 224, 2)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensorflow.python.framework.ops.EagerTensor"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BLNqqP_3b2kp",
        "colab_type": "text"
      },
      "source": [
        "##Define AUDIO Convolution\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3wyZIAsJsKth",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wlx7tiP4b2RB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "def discriminator_Audio():\n",
        "  model = tf.keras.Sequential()\n",
        "  model.add(layers.Conv2D(32, (3,3), strides = (1,1), padding = 'same', input_shape= [224,224,2]))\n",
        "  model.add(layers.LeakyReLU())\n",
        "\n",
        "  model.add(layers.MaxPooling2D(2, 2))\n",
        "  model.add(layers.Conv2D(64, (3,3), strides = (1,1), padding = 'same'))\n",
        "  model.add(layers.LeakyReLU())\n",
        "  \n",
        "  model.add(layers.MaxPooling2D(2, 2))\n",
        "  model.add(layers.Conv2D(128, (3,3), strides = (1,1), padding = 'same'))\n",
        "  model.add(layers.LeakyReLU())\n",
        "  model.add(layers.MaxPooling2D(2, 2))\n",
        "  for layer in model.layers:\n",
        "    aA=layer.output_shape\n",
        "    bA=layer.output\n",
        "    #print(aA)\n",
        "    #print(bA)\n",
        "  \n",
        "  return model\n",
        "\n",
        "\n",
        "\n",
        "discriminator_audio = discriminator_Audio()\n",
        "discriminator_audio(audioImage_dataSet)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OPiCWqaoMDz7",
        "colab_type": "text"
      },
      "source": [
        "#FINAL DISCRIMINATOR "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pw7CXriIMVMw",
        "colab_type": "text"
      },
      "source": [
        "##Discriminator concatenation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FZEbIazfMYtJ",
        "colab_type": "code",
        "outputId": "f6add459-e961-4db2-826e-13b57c4474a4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "image_conv = discriminator_image(image_dataset)\n",
        "audio_conv = discriminator_audio(audioImage_dataSet)\n",
        "\n",
        "#print(image_conv[0,0,0,0])\n",
        "#print(audio_conv[0,0,0,0])\n",
        "\n",
        "\n",
        "concatenation = tf.concat([image_conv, audio_conv], axis=3)\n",
        "print(concatenation.shape)\n",
        "#print(concatenation[0,0,0,128])\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(4, 28, 28, 256)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zbkE_CvRVuZg",
        "colab_type": "text"
      },
      "source": [
        "##Define FINAL Discriminator"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jBe10atbMRQX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def Final_discriminator_model():\n",
        "    model = tf.keras.Sequential()\n",
        "    model.add(layers.Conv2D(64, (5, 5), strides=(2, 2), padding='same', input_shape=[28, 28, 256]))\n",
        "    model.add(layers.LeakyReLU())\n",
        "    model.add(layers.Dropout(0.3))\n",
        "\n",
        "    model.add(layers.Conv2D(128, (5, 5), strides=(2, 2), padding='same'))\n",
        "    model.add(layers.LeakyReLU())\n",
        "    model.add(layers.Dropout(0.3))\n",
        "\n",
        "    model.add(layers.Flatten())\n",
        "    model.add(layers.Dense(1))\n",
        "\n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7e9QCCyRZjOW",
        "colab_type": "code",
        "outputId": "bce491a1-b681-4087-bb60-41369b2a8162",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "final_discriminator = Final_discriminator_model()\n",
        "output = final_discriminator(concatenation)\n",
        "#print (output)\n",
        "#print(output.shape)\n",
        "\n",
        "BUFFER_SIZE = 60000 \n",
        "BATCH_SIZE = 256\n",
        "\n",
        "train_dataset = tf.data.Dataset.from_tensor_slices(concatenation).shuffle(BUFFER_SIZE).batch(BATCH_SIZE)\n",
        "print(train_dataset)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<BatchDataset shapes: (None, 28, 28, 256), types: tf.float32>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eht87STsVbhW",
        "colab_type": "text"
      },
      "source": [
        "# Define **Generator**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VBFxOAI3U5Ew",
        "colab_type": "code",
        "outputId": "7b7261ce-20a7-4d15-caba-fe69f6d810f1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import tensorflow as tf\n",
        "import keras\n",
        "from keras.layers import Input, Conv2D, MaxPooling2D, GlobalMaxPooling2D, GlobalAveragePooling2D\n",
        "from keras.layers import Concatenate, Dense, LSTM, Flatten, RepeatVector, TimeDistributed, Dropout\n",
        "from keras.models import Model\n",
        "from keras.optimizers import Adam\n",
        "from keras.layers import Bidirectional, GaussianNoise, BatchNormalization\n",
        "from keras.layers import CuDNNLSTM as LSTM"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NzKOIh6dF9ah",
        "colab_type": "code",
        "outputId": "e1498ff3-4d8f-4f6d-ba9b-b17d2035907f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Generate to streams in the generator , de concatenation in the generator\n",
        "# upconv to (None, 28, 28, 256) and the split it in two streams inside \n",
        "# resphape an reconcate\n",
        "\n",
        "\n",
        "def deConcat(model):\n",
        "   \n",
        "  deConcatedModelAudio = np.ones([28,28,128])\n",
        "  deConcatedModelImage = np.ones([28,28,128])\n",
        "  tensor = model\n",
        "  #print(tensor.dtype)\n",
        "  \n",
        "  split0, split1 = tf.split(tensor, num_or_size_splits=2, axis=3)\n",
        "  tf.shape(split0)\n",
        "  tf.shape(split1)\n",
        "\n",
        "  deConcatedModelAudio = split0\n",
        "  deConcatedModelImage = split1\n",
        "  \n",
        "  #print(deConcatedModelAudio)\n",
        "  #print(deConcatedModelImage)\n",
        "\n",
        "\n",
        "  return deConcatedModelAudio , deConcatedModelImage\n",
        "\n",
        "\n",
        "def deConvolution_Audio():\n",
        "    model = tf.keras.Sequential()\n",
        "    model.add(layers.Conv2D(64, (5, 5), strides=(2, 2), padding='same', input_shape=[28, 28, 128]))\n",
        "    model.add(layers.LeakyReLU())\n",
        "    model.add(layers.Dropout(0.3))\n",
        "\n",
        "    model.add(layers.Reshape((7, 7, 256)))\n",
        "    assert model.output_shape == (None, 7, 7, 256) # Note: None is the batch size\n",
        "\n",
        "    model.add(layers.Conv2DTranspose(128, (5, 5), strides=(1, 1), padding='same', use_bias=False))\n",
        "    assert model.output_shape == (None, 7, 7, 128)\n",
        "    \n",
        "    model.add(layers.Conv2DTranspose(256, (5, 5), strides=(2, 2), padding='same', use_bias=False, activation='tanh'))\n",
        "    assert model.output_shape == (None, 14, 14, 256)\n",
        "\n",
        "    model.add(layers.Conv2DTranspose(128, (5, 5), strides=(2, 2), padding='same', use_bias=False, activation='tanh'))\n",
        "    assert model.output_shape == (None, 28, 28, 128)\n",
        "\n",
        "    model.add(layers.Conv2DTranspose(32, (5, 5), strides=(2, 2), padding='same', use_bias=False, activation='tanh'))\n",
        "    assert model.output_shape == (None, 56, 56, 32)\n",
        "    \n",
        "    model.add(layers.Conv2DTranspose(8, (5, 5), strides=(2, 2), padding='same', use_bias=False, activation='tanh'))\n",
        "    assert model.output_shape == (None, 112, 112, 8)\n",
        "    \n",
        "    model.add(layers.Conv2DTranspose(2, (5, 5), strides=(2, 2), padding='same', use_bias=False, activation='tanh'))\n",
        "    assert model.output_shape == (None, 224, 224, 2)\n",
        "    \n",
        "    #model.add(layers.Flatten())\n",
        "    #model.add(layers.Dense(1))\n",
        "\n",
        "    return model\n",
        "  \n",
        "ndarray = np.ones([4,28,28,128])\n",
        "#print(ndarray[1,1,1,1])\n",
        "ndarray = tf.cast(ndarray, 'float32')\n",
        "#print(ndarray.shape)\n",
        "deConvolution_Audio = deConvolution_Audio()\n",
        "deConvolution_Audio_Image = deConvolution_Audio(ndarray)\n",
        "#output.shape\n",
        "\n",
        "def deConvolution_Image():\n",
        "    model = tf.keras.Sequential()\n",
        "    model.add(layers.Conv2D(64, (5, 5), strides=(2, 2), padding='same', input_shape=[28, 28, 128]))\n",
        "    model.add(layers.LeakyReLU())\n",
        "    model.add(layers.Dropout(0.3))\n",
        "\n",
        "    model.add(layers.Reshape((7, 7, 256)))\n",
        "    assert model.output_shape == (None, 7, 7, 256) # Note: None is the batch size\n",
        "\n",
        "    model.add(layers.Conv2DTranspose(128, (5, 5), strides=(1, 1), padding='same', use_bias=False))\n",
        "    assert model.output_shape == (None, 7, 7, 128)\n",
        "    \n",
        "    model.add(layers.Conv2DTranspose(256, (5, 5), strides=(2, 2), padding='same', use_bias=False, activation='tanh'))\n",
        "    assert model.output_shape == (None, 14, 14, 256)\n",
        "\n",
        "    model.add(layers.Conv2DTranspose(128, (5, 5), strides=(2, 2), padding='same', use_bias=False, activation='tanh'))\n",
        "    assert model.output_shape == (None, 28, 28, 128)\n",
        "\n",
        "    model.add(layers.Conv2DTranspose(32, (5, 5), strides=(2, 2), padding='same', use_bias=False, activation='tanh'))\n",
        "    assert model.output_shape == (None, 56, 56, 32)\n",
        "    \n",
        "    model.add(layers.Conv2DTranspose(8, (5, 5), strides=(2, 2), padding='same', use_bias=False, activation='tanh'))\n",
        "    assert model.output_shape == (None, 112, 112, 8)\n",
        "    \n",
        "    model.add(layers.Conv2DTranspose(3, (5, 5), strides=(2, 2), padding='same', use_bias=False, activation='tanh'))\n",
        "    assert model.output_shape == (None, 224, 224, 3)\n",
        "    \n",
        "    #model.add(layers.Flatten())\n",
        "    #model.add(layers.Dense(1))\n",
        "\n",
        "    return model\n",
        "  \n",
        "ndarray = np.ones([4,28,28,128])\n",
        "#print(ndarray[1,1,1,1])\n",
        "ndarray = tf.cast(ndarray, 'float32')\n",
        "#print(ndarray.shape)\n",
        "deConvolution_Image = deConvolution_Image()\n",
        "deConvolution_Image_Image = deConvolution_Image(ndarray)\n",
        "#output.shape\n",
        "    \n",
        "\n",
        "\n",
        "def make_generator_model():\n",
        "    model = tf.keras.Sequential()\n",
        "    model.add(layers.Dense(7*7*256, use_bias=False, input_shape=(100,)))\n",
        "    model.add(layers.BatchNormalization())\n",
        "    model.add(layers.LeakyReLU())\n",
        "\n",
        "    model.add(layers.Reshape((7, 7, 256)))\n",
        "    assert model.output_shape == (None, 7, 7, 256) # Note: None is the batch size\n",
        "\n",
        "    model.add(layers.Conv2DTranspose(128, (5, 5), strides=(1, 1), padding='same', use_bias=False))\n",
        "    assert model.output_shape == (None, 7, 7, 128)\n",
        "    #model.add(layers.BatchNormalization())\n",
        "    #model.add(layers.LeakyReLU())\n",
        "\n",
        "    model.add(layers.Conv2DTranspose(64, (5, 5), strides=(2, 2), padding='same', use_bias=False))\n",
        "    assert model.output_shape == (None, 14, 14, 64)\n",
        "    #model.add(layers.BatchNormalization())\n",
        "    #model.add(layers.LeakyReLU())\n",
        "\n",
        "    model.add(layers.Conv2DTranspose(256, (5, 5), strides=(2, 2), padding='same', use_bias=False, activation='tanh'))\n",
        "    assert model.output_shape == (None, 28, 28, 256)\n",
        "    \n",
        "  \n",
        "    #[ log phase - 224,224,2]\n",
        "    #[ rgb - 224,224,3]\n",
        "    \n",
        "    return model\n",
        "  \n",
        "  \n",
        "  \n",
        "\n",
        "  \n",
        "noise = tf.random.normal([1, 100])\n",
        "generator = make_generator_model()\n",
        "generated_image = generator(noise, training=False)\n",
        "\n",
        "\n",
        "generated_image.shape\n",
        "#plt.imshow(generated_image[0, :, :, 0])\n",
        "\n",
        "\n",
        "#audioTensor, imageTensor = deConcat(model)\n",
        "    \n",
        "  \n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TensorShape([1, 28, 28, 256])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eDnpMkjSVz25",
        "colab_type": "text"
      },
      "source": [
        "#Training Functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NAvPL3XfDxjx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "noise_dim = 100\n",
        "num_examples_to_generate = 1\n",
        "#decision = Final_discriminator_model(generated_image)\n",
        "#print (decision)\n",
        "\n",
        "# This method returns a helper function to compute cross entropy loss\n",
        "cross_entropy = tf.keras.losses.BinaryCrossentropy(from_logits=True)\n",
        "\n",
        "\n",
        "\n",
        "def discriminator_loss(real_output, fake_output):\n",
        "    real_loss = cross_entropy(tf.ones_like(real_output), real_output)\n",
        "    fake_loss = cross_entropy(tf.zeros_like(fake_output), fake_output)\n",
        "    total_loss = real_loss + fake_loss\n",
        "    return total_loss\n",
        "  \n",
        "def generator_loss(fake_output):\n",
        "    return cross_entropy(tf.ones_like(fake_output), fake_output)\n",
        "  \n",
        "generator_optimizer = tf.keras.optimizers.Adam(1e-4)\n",
        "discriminator_optimizer = tf.keras.optimizers.Adam(1e-4)\n",
        "\n",
        "\n",
        "checkpoint_dir = './training_checkpoints'\n",
        "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt\")\n",
        "checkpoint = tf.train.Checkpoint(generator_optimizer=generator_optimizer,\n",
        "                                 discriminator_optimizer=discriminator_optimizer,\n",
        "                                 generator=generator,\n",
        "                                 discriminator=final_discriminator)\n",
        "\n",
        "\n",
        "\n",
        "# We will reuse this seed overtime (so it's easier)\n",
        "# to visualize progress in the animated GIF)\n",
        "seed = tf.random.normal([num_examples_to_generate, noise_dim])\n",
        "\n",
        "# Notice the use of `tf.function`\n",
        "# This annotation causes the function to be \"compiled\".\n",
        "@tf.function\n",
        "def train_step(images):\n",
        "    noise = tf.random.normal([BATCH_SIZE, noise_dim])\n",
        "\n",
        "    with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n",
        "      generated_images = generator(noise, training=True)\n",
        "\n",
        "      real_output = final_discriminator(images, training=True)\n",
        "      fake_output = final_discriminator(generated_images, training=True)\n",
        "\n",
        "      gen_loss = generator_loss(fake_output)\n",
        "      disc_loss = discriminator_loss(real_output, fake_output)\n",
        "\n",
        "    gradients_of_generator = gen_tape.gradient(gen_loss, generator.trainable_variables)\n",
        "    gradients_of_discriminator = disc_tape.gradient(disc_loss, final_discriminator.trainable_variables)\n",
        "\n",
        "    generator_optimizer.apply_gradients(zip(gradients_of_generator, generator.trainable_variables))\n",
        "    discriminator_optimizer.apply_gradients(zip(gradients_of_discriminator, final_discriminator.trainable_variables))\n",
        "    \n",
        "    \n",
        "def train(dataset, epochs):\n",
        "  for epoch in range(epochs):\n",
        "    start = time.time()\n",
        "\n",
        "    for image_batch in dataset:\n",
        "      train_step(image_batch)\n",
        "\n",
        "    # Produce images for the GIF as we go\n",
        "    display.clear_output(wait=True)\n",
        "    generate_and_save_images(generator,\n",
        "                             epoch + 1,\n",
        "                             seed)\n",
        "\n",
        "    # Save the model every 15 epochs\n",
        "    if (epoch + 1) % 500 == 0:\n",
        "      checkpoint.save(file_prefix = checkpoint_prefix)\n",
        "\n",
        "    print ('Time for epoch {} is {} sec'.format(epoch + 1, time.time()-start))\n",
        "\n",
        "  # Generate after the final epoch\n",
        "  display.clear_output(wait=True)\n",
        "  generate_and_save_images(generator, epochs, seed)\n",
        "  \n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NowuHDW0V_jG",
        "colab_type": "text"
      },
      "source": [
        "##Save training output"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xrxmGJYBWBbv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#PUFFER IMAGE EXTERN???  \n",
        "#pufferImg = np.ndarray((224,224,3))\n",
        "\n",
        "# ATTENTION: NOT SURE ABOUT [0,:,:,:] -> what does the 0 do ????\n",
        "\n",
        "from matplotlib.pyplot import figure, imshow, axis\n",
        "from matplotlib.image import imread\n",
        "\n",
        "def generate_and_save_images(model, epoch, test_input):\n",
        "  # Notice `training` is set to False.\n",
        "  # This is so all layers run in inference mode (batchnorm).\n",
        "  predictions = model(test_input, training=False)\n",
        "  #print(predictions.shape)\n",
        "  \n",
        "  \n",
        "  # CONCAT CONVOL\n",
        "  \n",
        "  audio_model, image_model = deConcat(predictions)\n",
        "  \n",
        "  #print(audio_model.shape, image_model.shape)\n",
        "  \n",
        "  audio_output = deConvolution_Audio(audio_model)\n",
        "  image_output = deConvolution_Image(image_model)\n",
        "  \n",
        "  #print('audio_output',audio_output.shape,'image_output',image_output.shape)\n",
        "  \n",
        "  \n",
        "  pufferImg = np.ndarray((224,224,3))\n",
        "  #pufferImg[:,:,:] = image_output[0,:,:,:] \n",
        "  pufferImg = image_output[0,:,:,:] * 127.5 + 127.5\n",
        "  pufferImg = pufferImg[:,:,:]\n",
        "    \n",
        "    \n",
        "  pufferPhase = np.ndarray((224,224))\n",
        "  pufferLog = np.ndarray((224,224))\n",
        "  \n",
        "  pufferPhase[:,:] = audio_output[0,:,:,0]\n",
        "  pufferLog[:,:] = audio_output[0,:,:,1]\n",
        "  \n",
        "  \n",
        "  plt.figure(figsize=(10,10))\n",
        "\n",
        "  # IMAGE    \n",
        "  plt.subplot(131)  \n",
        "  plt.title('RGB-Image')\n",
        "  plt.imshow(pufferImg)\n",
        "  plt.axis('off')\n",
        "  #plt.savefig('./image_output/image_at_epoch_{:04d}.png'.format(epoch))\n",
        "    \n",
        "    \n",
        "  # AUDIO\n",
        "\n",
        "  plt.subplot(132)  \n",
        "  plt.title('PHASE-IMAGE')  \n",
        "  plt.imshow(pufferPhase, cmap='gray')\n",
        "  plt.axis('off')\n",
        "  #plt.savefig('./audio_output/phase_at_epoch_{:04d}.png'.format(epoch))\n",
        "\n",
        "  plt.subplot(133)\n",
        "  plt.title('LOG-IMAGE')\n",
        "  plt.imshow(pufferLog, cmap='gray')\n",
        "  plt.axis('off')\n",
        "  #plt.savefig('./audio_output/log_at_epoch_{:04d}.png'.format(epoch))\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  #plt.show()\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EXxd39OBZpMz",
        "colab_type": "text"
      },
      "source": [
        "#TRAINING"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x_9zCt4O1OEU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "EPOCHS = 3000"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a8nria5Uvfov",
        "colab_type": "code",
        "outputId": "4845e4a7-2538-452c-c910-f4a501a62eef",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "%%time\n",
        "train(train_dataset, EPOCHS)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "W0722 23:00:06.696436 139669212694400 image.py:648] Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EP6YusEjlBdz",
        "colab_type": "text"
      },
      "source": [
        "#After training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g7AyiTrBBoaH",
        "colab_type": "code",
        "outputId": "64e39f01-a11a-4546-9ea9-f0d30feae940",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "checkpoint.restore(tf.train.latest_checkpoint(checkpoint_dir))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x7f068333b3c8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qsUYXWKRZ3Aa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Display a single image using the epoch number\n",
        "def display_image(epoch_no):\n",
        "  return PIL.Image.open('TrainedImages/image_at_epoch_{:04d}.png'.format(epoch_no))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gk0nlFbvZ3sY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "anim_file = 'AVGAN.gif'\n",
        "\n",
        "with imageio.get_writer(anim_file, mode='I') as writer:\n",
        "  #filenames = glob.glob('image*.png')\n",
        "  filenames = glob.glob('./image_output/image*.png')\n",
        "  #filenames = glob.glob('./audio_output/log*.png')\n",
        "  #filenames = glob.glob('./audio_output/phase*.png')\n",
        "  \n",
        "  filenames = sorted(filenames)\n",
        "  last = -1\n",
        "  for i,filename in enumerate(filenames):\n",
        "    frame = 2*(i**0.5)\n",
        "    if round(frame) > round(last):\n",
        "      last = frame\n",
        "    else:\n",
        "      continue\n",
        "    image = imageio.imread(filename)\n",
        "    writer.append_data(image)\n",
        "  image = imageio.imread(filename)\n",
        "  writer.append_data(image)\n",
        "\n",
        "import IPython\n",
        "if IPython.version_info > (6,2,0,''):\n",
        "  display.Image(filename=anim_file)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WenctI1EZ726",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "try:\n",
        "  from google.colab import files\n",
        "except ImportError:\n",
        "  pass\n",
        "else:\n",
        "  files.download(anim_file)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}